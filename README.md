# LearnADo

AI-powered learning assistant for document processing and analysis.

## ğŸ¯ Phase 1: Setup & Preprocessing Layer

**Goal**: Convert all types of user input (text, PDF, image, audio) into machine-readable text for further AI processing.

### Current Focus
This project is currently in **Phase 1** development, focusing on building a robust preprocessing layer that can handle multiple input formats and convert them into clean, machine-readable text.

## ğŸš€ Features (Phase 1)

### Input Processing Capabilities
- **Text Input** â†’ Direct text processing and validation
- **PDF Processing** â†’ Text extraction using pdfplumber and PyMuPDF
- **Image OCR** â†’ Text extraction from images using pytesseract
- **Audio Transcription** â†’ Speech-to-Text conversion using OpenAI Whisper
- **Language Translation** â†’ Multi-language support using HuggingFace MarianMT

### Core Functionality
- **Unified API** â†’ Single endpoint to handle all input types
- **Text Extraction** â†’ Clean, structured text output from any input
- **Language Detection** â†’ Automatic language identification
- **Translation Pipeline** â†’ Convert content between languages
- **File Management** â†’ Secure upload, processing, and storage

## ğŸ—ï¸ Project Structure

```
LearnADo/
â”œâ”€â”€ main.py                  # FastAPI entrypoint
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # Project documentation
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py         # Package initialization
â”‚   â”œâ”€â”€ database.py         # Database setup and configuration
â”‚   â”œâ”€â”€ models.py           # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ schemas.py          # Pydantic request/response schemas
â”‚   â”œâ”€â”€ routes.py           # API endpoints and routing
â”‚   â”œâ”€â”€ services.py         # Preprocessing logic (PDF, image, audio, translation)
â”‚   â””â”€â”€ utils.py            # Helper functions (OCR, STT, translation)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/            # Uploaded raw files
â”‚   â””â”€â”€ processed/          # Extracted text outputs
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_app.py         # Unit tests
```

## ğŸ› ï¸ Technology Stack (Phase 1)

### Backend Framework
- **FastAPI** - Modern, fast web framework for APIs
- **SQLAlchemy** - Database ORM and integration
- **Pydantic** - Data validation and serialization

### Text Extraction & Processing
- **pdfplumber** - PDF text extraction
- **PyMuPDF** - Advanced PDF processing
- **pytesseract** - OCR for image text extraction
- **Pillow** - Image processing and manipulation

### Speech-to-Text
- **OpenAI Whisper** - High-quality audio transcription
- **HuggingFace Whisper** - Alternative STT implementation

### Translation & NLP
- **HuggingFace Transformers** - MarianMT for translation
- **Sentence Transformers** - Text embeddings and similarity
- **LangChain** - AI/ML pipeline orchestration

### Database & Storage
- **SQLite** - Lightweight database for development
- **File System** - Local file storage for uploads and outputs

## ğŸ“‹ API Endpoints (Phase 1)

### File Upload & Processing
- `POST /api/v1/upload` - Upload files (text, PDF, image, audio)
- `POST /api/v1/process/{upload_id}` - Start text extraction
- `GET /api/v1/process/{upload_id}/status` - Check processing status
- `GET /api/v1/process/{upload_id}/result` - Get extracted text

### File Management
- `GET /api/v1/uploads` - List all uploaded files
- `GET /api/v1/uploads/{id}` - Get specific upload details
- `DELETE /api/v1/uploads/{id}` - Delete an upload

### Translation
- `POST /api/v1/translate` - Translate extracted text
- `GET /api/v1/languages` - Get supported languages

### Utilities
- `GET /` - API information
- `GET /health` - Health check
- `GET /docs` - Interactive API documentation

## ğŸš€ Setup Instructions

### Prerequisites

- Python 3.12+
- uv (Python package manager)
- Tesseract OCR (for image processing)
- FFmpeg (for audio processing)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd LearnADo
   ```

2. **Create virtual environment**
   ```bash
   uv venv
   source myenv/bin/activate  # On Windows: myenv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   uv pip install -r requirements.txt
   ```

4. **Install system dependencies**
   ```bash
   # For Tesseract OCR (Ubuntu/Debian)
   sudo apt-get install tesseract-ocr
   
   # For FFmpeg (Ubuntu/Debian)
   sudo apt-get install ffmpeg
   ```

5. **Run the application**
   ```bash
   python main.py
   ```

The API will be available at `http://localhost:8000`

## ğŸ“Š Phase 1 Milestones

### âœ… Completed
- [x] Project environment setup (virtualenv, FastAPI backend)
- [x] Database schema design
- [x] Project structure and file organization
- [x] Dependencies installation and configuration

### ğŸ”„ In Progress
- [ ] Text input processing implementation
- [ ] PDF processing with pdfplumber/PyMuPDF
- [ ] Image OCR with pytesseract
- [ ] Audio STT with Whisper
- [ ] Translation with MarianMT

### ğŸ“‹ Upcoming
- [ ] API endpoint implementation
- [ ] Error handling and validation
- [ ] File upload and storage
- [ ] Processing pipeline integration
- [ ] Unit tests and documentation

## ğŸ¯ Deliverables (Phase 1)

### Backend APIs
- **Unified Upload API** - Accept text, image, PDF, audio files
- **Text Extraction API** - Return clean, extracted text from any input
- **Translation API** - Convert text between supported languages
- **Status API** - Monitor processing progress

### Processing Capabilities
- **Text Input** â†’ Direct processing and validation
- **PDF Files** â†’ Text extraction with layout preservation
- **Images** â†’ OCR text extraction with confidence scoring
- **Audio Files** â†’ High-quality transcription with timestamps
- **Multi-language** â†’ Automatic language detection and translation

## ğŸ”§ Development

### Running Tests
```bash
pytest tests/
```

### Code Style
The project follows PEP 8 standards. Use a linter like `flake8` or `black` for code formatting.

### API Documentation
Once running, visit `http://localhost:8000/docs` for interactive API documentation.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“ License

[Add your license here]

## ğŸ†˜ Support

For support and questions, please open an issue on GitHub.

## ğŸ”® Future Phases

### Phase 2: AI Analysis Layer
- Text summarization and key point extraction
- Content classification and tagging
- Question-answering capabilities
- Knowledge graph generation

### Phase 3: Learning Enhancement
- Personalized learning recommendations
- Interactive study materials
- Progress tracking and analytics
- Collaborative learning features
